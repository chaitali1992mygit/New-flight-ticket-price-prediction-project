{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Price Prediction Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\chaitali nakade\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\chaitali nakade\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "#install selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all neccessory libreries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Edge(\"msedgedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.yatra.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nagpur to Mumbai flight details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "search_source =web_driver.find_element_by_xpath(\"//label[@class='inp-focus']\")\n",
    "search_source.send_keys('Nagpur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used destination \n",
    "search_destination =web_driver.find_element_by_xpath(\"//label[@class='inp-focus']\")\n",
    "search_destination.send_keys('Mumbai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for date selection\n",
    "search_date =web_driver.find_element_by_id(\"29/11/2021\")\n",
    "search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for date selection\n",
    "select_date =web_driver.find_element_by_id(\"29/11/2021\")\n",
    "select_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for date selection\n",
    "search =web_driver.find_element_by_id(\"BE_flight_flsearch_btn\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "Airline_name = [] #empty list\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "Flight_code = [] #empty list\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "Journey_date = [] #empty list\n",
    "for i in date:\n",
    "    Journey_date.append('29/11/2021')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "SourCE = [] #empty list\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "DestinatiON = [] #empty list\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "Departure_time = [] #empty list\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "Arrival_time = [] #empty list\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "Duration = [] #empty list\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "Total_Stops = [] #empty list\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "Price = [] #empty list\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 104 104 104 104 104 104 104 104 104\n"
     ]
    }
   ],
   "source": [
    "print(len(Airline_name), len(Flight_code), len(Journey_date), len(SourCE), len(DestinatiON), len(Departure_time), len(Arrival_time), len(Duration), len(Total_Stops), len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-1']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('01/12/2021')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('08/12/2021')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-3']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('15/12/2021')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-4']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('22/12/2021')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-5']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('29/12/2021')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('5/01/2022')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-4']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('19/01/2022')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('09/02/2022')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-4']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('23/02/2022')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('09/02/2022')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    Airline_name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_date.append('06/04/2022')\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SourCE.append(i.text)\n",
    "\n",
    "for i in source[1: :2]:\n",
    "    DestinatiON.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    Departure_time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    Arrival_time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    Duration.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_Stops.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mumbai to New Delhi flight details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Source =web_driver.find_element_by_xpath(\"//div[@class='input-holder pb-2 bdr-btm']\")\n",
    "Source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Source_Name =web_driver.find_element_by_xpath(\"//input[@class='fs-16 bold ng-touched ng-dirty ellipsis full-width ng-not-empty ng-valid ng-valid-required']\")\n",
    "Source_Name.send_keys('Mumbai(BOM)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Date =web_driver.find_element_by_xpath(\"//p[@class='full day-holder  text-success']\")\n",
    "Date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "search =web_driver.find_element_by_xpath(\"//button[@class='fs-14 btn-submit cursor-pointer bold']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "AIRLINE_NAME=[]\n",
    "for i in airlines:\n",
    "    AIRLINE_NAME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "Flight_Code = []\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_Code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "Journey_Date = []\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_Date.append('29/11/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "SOURCE = []\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE.append(i.text)\n",
    "\n",
    "DESTINATION = []\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "DEPARTURE_TIME = []\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_TIME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "ARRIVAL_TIME = []\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_TIME.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "DURATION = []\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DURATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "TOTAL_STOPS = []\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    TOTAL_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "PRICE = []\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-1']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_NAME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_Code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_Date.append('01/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_TIME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_TIME.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DURATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    TOTAL_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_NAME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_Code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_Date.append('08/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_TIME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_TIME.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DURATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    TOTAL_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-3']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_NAME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_Code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_Date.append('22/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_TIME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_TIME.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DURATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    TOTAL_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-4']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_NAME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_Code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_Date.append('22/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_TIME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_TIME.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DURATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    TOTAL_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_NAME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_Code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_Date.append('05/01/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_TIME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_TIME.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DURATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    TOTAL_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-4']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_NAME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_Code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_Date.append('19/01/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_TIME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_TIME.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DURATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    TOTAL_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-4']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_NAME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_Code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_Date.append('22/02/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_TIME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_TIME.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DURATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    TOTAL_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-1']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_NAME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    Flight_Code.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    Journey_Date.append('04/05/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_TIME.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_TIME.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DURATION.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    TOTAL_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666 666 666 666 666 666 666 666 666 666\n"
     ]
    }
   ],
   "source": [
    "print(len(AIRLINE_NAME), len(Flight_Code), len(Journey_Date), len(SOURCE), len(DESTINATION), len(DEPARTURE_TIME), len(ARRIVAL_TIME), len(DURATION), len(TOTAL_STOPS), len(PRICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Banglore to Ahmedabad flight details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Source =web_driver.find_element_by_xpath(\"//div[@class='input-holder pb-2 bdr-btm']\")\n",
    "Source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Source_Name =web_driver.find_element_by_xpath(\"//input[@class='fs-16 bold ng-touched ng-dirty ellipsis full-width ng-not-empty ng-valid ng-valid-required']\")\n",
    "Source_Name.send_keys('Bangalore(BLR)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Destination_Name =web_driver.find_element_by_xpath(\"//input[@class='fs-16 bold ng-touched ng-dirty ellipsis full-width ng-not-empty ng-valid ng-valid-required']\")\n",
    "Destination_Name.send_keys('Ahmedabad(AMD)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Date =web_driver.find_element_by_xpath(\"//p[@class='full day-holder  text-success']\")\n",
    "Date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "search =web_driver.find_element_by_xpath(\"//button[@class='fs-14 btn-submit cursor-pointer bold']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "AIRLINE_Name=[]\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "FLIGHT_CODE = []\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "JOURNEY_DATE = []\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('29/11/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "SOURCE_BA = []\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "DESTINATION_BA = []\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "DEPARTURE_Time = []\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "ARRIVAL_Time = []\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "DuratioN = []\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "Total_STOPS = []\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "PricE = []\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-1']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('01/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('08/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-3']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('15/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-4']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('22/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-5']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('29/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-3']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('12/01/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-5']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('27/01/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-1']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('02/02/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-4']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('23/02/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105 1105 1105 1105 1105 1105 1105 1105 1105 1105\n"
     ]
    }
   ],
   "source": [
    "print(len(AIRLINE_Name), len(FLIGHT_CODE), len(JOURNEY_DATE), len(SOURCE_BA), len(DESTINATION_BA), len(DEPARTURE_Time), len(ARRIVAL_Time), len(DuratioN), len(Total_STOPS), len(PricE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Delhi to Kolkata flight Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Source =web_driver.find_element_by_xpath(\"//div[@class='input-holder pb-2 bdr-btm']\")\n",
    "Source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Source_Name =web_driver.find_element_by_xpath(\"//input[@class='fs-16 bold ng-touched ng-dirty ellipsis full-width ng-not-empty ng-valid ng-valid-required']\")\n",
    "Source_Name.send_keys('New Delhi(DEL)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Source_Name =web_driver.find_element_by_xpath(\"//input[@class='fs-16 bold ng-touched ng-dirty ellipsis full-width ng-not-empty ng-valid ng-valid-required']\")\n",
    "Source_Name.send_keys('Kolkata (CCU))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Date =web_driver.find_element_by_xpath(\"//p[@class='full day-holder  text-success']\")\n",
    "Date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "search =web_driver.find_element_by_xpath(\"//button[@class='fs-14 btn-submit cursor-pointer bold']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('29/11/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('08/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-3']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('15/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-5']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('29/12/2021')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-2']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('05/01/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-5']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('26/01/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//p[@class='bold font-lightgrey fs-8 mt-2 text-uppercase']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//span[@class='ytfi-angle-right']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find element for used depart from\n",
    "Search_date =web_driver.find_element_by_xpath(\"//tr[@class='week week-3']\")\n",
    "Search_date.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Airline_name\n",
    "airlines = web_driver.find_elements_by_xpath(\"//span[@class='i-b text ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in airlines:\n",
    "    AIRLINE_Name.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Flight code\n",
    "code = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in code:\n",
    "    FLIGHT_CODE.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having date of journey\n",
    "date = web_driver.find_elements_by_xpath(\"//p[@class='normal fs-11 font-lightestgrey no-wrap fl-no']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in date:\n",
    "    JOURNEY_DATE.append('16/03/2022')\n",
    "\n",
    "\n",
    "\n",
    "#extract the tag having source\n",
    "source = web_driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in source[0: :2]:\n",
    "    SOURCE_BA.append(i.text)\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "for i in source[1: :2]:\n",
    "    DESTINATION_BA.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having departure time\n",
    "Departure = web_driver.find_elements_by_xpath(\"//div[@class='i-b pr']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Departure:\n",
    "    DEPARTURE_Time.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having Arrival time\n",
    "Arrival = web_driver.find_elements_by_xpath(\"//p[@class='bold fs-15 mb-2 pr time']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Arrival:\n",
    "    ARRIVAL_Time.append(i.text.replace(\"\\n+ 1 day\", ''))\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "duration = web_driver.find_elements_by_xpath(\"//p[@class='fs-12 bold du mb-2']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in duration:\n",
    "    DuratioN.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "Stops = web_driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in Stops:\n",
    "    Total_STOPS.append(i.text)\n",
    "\n",
    "\n",
    "#extract the tag having duration time\n",
    "price = web_driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\")\n",
    "#to remove extra data other than output we required\n",
    "for i in price:\n",
    "    PricE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2106 2106 2106 2106 2106 2106 2106 2106 2106 2106\n"
     ]
    }
   ],
   "source": [
    "print(len(AIRLINE_Name), len(FLIGHT_CODE), len(JOURNEY_DATE), len(SOURCE_BA), len(DESTINATION_BA), len(DEPARTURE_Time), len(ARRIVAL_Time), len(DuratioN), len(Total_STOPS), len(PricE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRLINES_NAME = Airline_name + AIRLINE_NAME + AIRLINE_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLIGHTS_CODE = Flight_code + Flight_Code + FLIGHT_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_OF_JOURNEY = Journey_date + Journey_Date + JOURNEY_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES = SourCE + SOURCE + SOURCE_BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATIONS = DestinatiON + DESTINATION + DESTINATION_BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPARTURE_T = Departure_time + DEPARTURE_TIME + DEPARTURE_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARRIVAL_T = Arrival_time + ARRIVAL_TIME + ARRIVAL_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "DURATIONS = Duration + DURATION + DuratioN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_STOPS = Total_Stops + TOTAL_STOPS + Total_STOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLIGHT_PRICE = Price + PRICE + PricE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4104 4104 4104 4104 4104 4104 4104 4104 4104 4104\n"
     ]
    }
   ],
   "source": [
    "print(len(AIRLINES_NAME),len(FLIGHTS_CODE), len(DATE_OF_JOURNEY), len(SOURCES), len(DESTINATIONS), len(DEPARTURE_T), len(ARRIVAL_T), len(DURATIONS), len(TOTAL_STOPS), len(FLIGHT_PRICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4104"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DURATION = [] #empty list\n",
    "for i in DURATIONS:\n",
    "    DURATION.append(i.replace('h ', ':').replace('m', ''))\n",
    "len(DURATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4,566',\n",
       " '4,566',\n",
       " '4,566',\n",
       " '4,567',\n",
       " '4,567',\n",
       " '4,567',\n",
       " '4,724',\n",
       " '5,511',\n",
       " '5,926',\n",
       " '8,724',\n",
       " '9,239',\n",
       " '9,606',\n",
       " '10,394',\n",
       " '11,465',\n",
       " '11,848',\n",
       " '21,314',\n",
       " '4,566',\n",
       " '4,567',\n",
       " '4,567',\n",
       " '4,567',\n",
       " '4,724',\n",
       " '5,196',\n",
       " '5,511',\n",
       " '5,511',\n",
       " '7,740',\n",
       " '7,740',\n",
       " '7,740',\n",
       " '7,740',\n",
       " '8,189',\n",
       " '8,504',\n",
       " '8,546',\n",
       " '9,186',\n",
       " '9,386',\n",
       " '9,706',\n",
       " '9,706',\n",
       " '11,741',\n",
       " '11,804',\n",
       " '11,916',\n",
       " '11,916',\n",
       " '11,916',\n",
       " '11,916',\n",
       " '11,916',\n",
       " '11,916',\n",
       " '13,064',\n",
       " '13,064',\n",
       " '13,176',\n",
       " '13,176',\n",
       " '14,334',\n",
       " '15,801',\n",
       " '16,116',\n",
       " '16,431',\n",
       " '16,641',\n",
       " '19,826',\n",
       " '4,566',\n",
       " '4,566',\n",
       " '4,567',\n",
       " '4,567',\n",
       " '4,724',\n",
       " '4,724',\n",
       " '4,881',\n",
       " '5,196',\n",
       " '5,196',\n",
       " '7,717',\n",
       " '7,717',\n",
       " '7,740',\n",
       " '7,740',\n",
       " '7,741',\n",
       " '8,651',\n",
       " '8,869',\n",
       " '9,181',\n",
       " '9,181',\n",
       " '9,181',\n",
       " '9,181',\n",
       " '9,181',\n",
       " '9,181',\n",
       " '9,268',\n",
       " '9,449',\n",
       " '10,205',\n",
       " '10,205',\n",
       " '10,446',\n",
       " '10,961',\n",
       " '11,562',\n",
       " '12,717',\n",
       " '12,717',\n",
       " '13,814',\n",
       " '14,034',\n",
       " '14,139',\n",
       " '14,623',\n",
       " '21,149',\n",
       " '4,566',\n",
       " '4,567',\n",
       " '4,567',\n",
       " '4,567',\n",
       " '5,511',\n",
       " '5,926',\n",
       " '5,926',\n",
       " '5,926',\n",
       " '7,609',\n",
       " '7,609',\n",
       " '7,717',\n",
       " '7,717',\n",
       " '7,717',\n",
       " '7,717',\n",
       " '8,756',\n",
       " '8,861',\n",
       " '9,181',\n",
       " '9,181',\n",
       " '9,268',\n",
       " '9,666',\n",
       " '10,205',\n",
       " '10,205',\n",
       " '10,205',\n",
       " '10,446',\n",
       " '11,045',\n",
       " '11,045',\n",
       " '11,276',\n",
       " '11,279',\n",
       " '13,137',\n",
       " '13,484',\n",
       " '14,135',\n",
       " '14,376',\n",
       " '15,245',\n",
       " '3,086',\n",
       " '3,086',\n",
       " '3,253',\n",
       " '3,253',\n",
       " '3,254',\n",
       " '3,254',\n",
       " '3,569',\n",
       " '3,884',\n",
       " '3,884',\n",
       " '5,091',\n",
       " '5,091',\n",
       " '5,788',\n",
       " '5,970',\n",
       " '5,970',\n",
       " '6,058',\n",
       " '6,058',\n",
       " '6,058',\n",
       " '6,390',\n",
       " '6,390',\n",
       " '6,390',\n",
       " '6,390',\n",
       " '6,442',\n",
       " '7,407',\n",
       " '7,454',\n",
       " '7,755',\n",
       " '7,769',\n",
       " '7,811',\n",
       " '8,409',\n",
       " '8,490',\n",
       " '8,934',\n",
       " '10,509',\n",
       " '10,961',\n",
       " '12,179',\n",
       " '12,935',\n",
       " '21,020',\n",
       " '2,697',\n",
       " '2,697',\n",
       " '2,771',\n",
       " '3,253',\n",
       " '3,254',\n",
       " '3,254',\n",
       " '3,254',\n",
       " '3,401',\n",
       " '4,409',\n",
       " '4,475',\n",
       " '4,590',\n",
       " '4,724',\n",
       " '5,037',\n",
       " '5,579',\n",
       " '5,699',\n",
       " '5,970',\n",
       " '5,970',\n",
       " '5,970',\n",
       " '6,390',\n",
       " '6,390',\n",
       " '6,915',\n",
       " '6,915',\n",
       " '7,335',\n",
       " '7,464',\n",
       " '7,591',\n",
       " '7,591',\n",
       " '7,591',\n",
       " '7,811',\n",
       " '8,409',\n",
       " '8,490',\n",
       " '9,879',\n",
       " '10,331',\n",
       " '10,471',\n",
       " '14,352',\n",
       " '16,431',\n",
       " '20,075',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '2,193',\n",
       " '2,421',\n",
       " '2,421',\n",
       " '2,697',\n",
       " '3,338',\n",
       " '4,500',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,833',\n",
       " '6,386',\n",
       " '6,453',\n",
       " '6,453',\n",
       " '6,453',\n",
       " '6,614',\n",
       " '7,181',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '9,389',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '2,697',\n",
       " '2,697',\n",
       " '2,771',\n",
       " '3,338',\n",
       " '3,338',\n",
       " '3,338',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,413',\n",
       " '5,413',\n",
       " '6,176',\n",
       " '6,453',\n",
       " '6,453',\n",
       " '6,453',\n",
       " '6,939',\n",
       " '7,181',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '8,565',\n",
       " '8,934',\n",
       " '9,774',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '2,193',\n",
       " '2,421',\n",
       " '2,421',\n",
       " '3,086',\n",
       " '3,086',\n",
       " '3,086',\n",
       " '3,086',\n",
       " '4,203',\n",
       " '4,738',\n",
       " '4,738',\n",
       " '4,738',\n",
       " '4,738',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,413',\n",
       " '5,413',\n",
       " '5,413',\n",
       " '7,181',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '7,989',\n",
       " '8,493',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '8,985',\n",
       " '18,384',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '2,193',\n",
       " '2,280',\n",
       " '2,697',\n",
       " '2,697',\n",
       " '2,697',\n",
       " '2,697',\n",
       " '4,738',\n",
       " '4,738',\n",
       " '4,738',\n",
       " '4,738',\n",
       " '4,738',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,413',\n",
       " '6,106',\n",
       " '6,176',\n",
       " '6,519',\n",
       " '7,601',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '8,025',\n",
       " '8,129',\n",
       " '8,934',\n",
       " '9,774',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '2,193',\n",
       " '2,697',\n",
       " '2,697',\n",
       " '2,697',\n",
       " '2,697',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,281',\n",
       " '6,106',\n",
       " '6,908',\n",
       " '7,674',\n",
       " '7,697',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '8,129',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '9,260',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '2,193',\n",
       " '2,280',\n",
       " '2,697',\n",
       " '3,086',\n",
       " '3,086',\n",
       " '3,086',\n",
       " '3,086',\n",
       " '4,394',\n",
       " '4,394',\n",
       " '4,394',\n",
       " '4,394',\n",
       " '4,394',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,716',\n",
       " '5,833',\n",
       " '6,176',\n",
       " '6,939',\n",
       " '7,601',\n",
       " '7,697',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '8,129',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '9,346',\n",
       " '9,346',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '2,193',\n",
       " '3,086',\n",
       " '3,086',\n",
       " '4,394',\n",
       " '4,394',\n",
       " '4,394',\n",
       " '4,394',\n",
       " '4,394',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '6,176',\n",
       " '6,299',\n",
       " '7,601',\n",
       " '7,697',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '8,129',\n",
       " '8,399',\n",
       " '8,399',\n",
       " '8,399',\n",
       " '8,934',\n",
       " '10,824',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '4,475',\n",
       " '4,475',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '4,947',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '6,176',\n",
       " '6,299',\n",
       " '6,299',\n",
       " '6,729',\n",
       " '7,697',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '8,129',\n",
       " '8,850',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '9,080',\n",
       " '9,080',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '2,193',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '6,176',\n",
       " '6,176',\n",
       " '6,729',\n",
       " '7,548',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '7,858',\n",
       " '8,129',\n",
       " '8,129',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '10,404',\n",
       " '10,404',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,175',\n",
       " '2,193',\n",
       " '2,193',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '5,098',\n",
       " '6,176',\n",
       " '6,176',\n",
       " '6,729',\n",
       " '7,548',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '7,853',\n",
       " '7,858',\n",
       " '8,129',\n",
       " '8,129',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '8,934',\n",
       " '10,404',\n",
       " '10,404',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,870',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,944',\n",
       " '5,944',\n",
       " '6,048',\n",
       " '6,048',\n",
       " '6,048',\n",
       " '6,153',\n",
       " '6,363',\n",
       " '6,363',\n",
       " '6,363',\n",
       " '6,364',\n",
       " '6,468',\n",
       " '6,520',\n",
       " '6,521',\n",
       " '8,043',\n",
       " '8,296',\n",
       " '8,296',\n",
       " '8,296',\n",
       " '8,673',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,988',\n",
       " '8,988',\n",
       " '9,146',\n",
       " '9,198',\n",
       " '9,198',\n",
       " '9,513',\n",
       " '9,723',\n",
       " '9,723',\n",
       " '9,828',\n",
       " '9,828',\n",
       " '9,828',\n",
       " '9,828',\n",
       " '9,933',\n",
       " '10,143',\n",
       " '10,396',\n",
       " '10,418',\n",
       " '10,458',\n",
       " '10,563',\n",
       " '10,563',\n",
       " '10,668',\n",
       " '10,716',\n",
       " '10,764',\n",
       " '11,167',\n",
       " '11,298',\n",
       " '11,298',\n",
       " '11,298',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,508',\n",
       " '11,928',\n",
       " '11,928',\n",
       " '11,928',\n",
       " '12,033',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,243',\n",
       " '12,243',\n",
       " '12,606',\n",
       " '13,451',\n",
       " '13,871',\n",
       " '15,078',\n",
       " '15,078',\n",
       " '15,918',\n",
       " '16,339',\n",
       " '16,443',\n",
       " '16,707',\n",
       " '18,727',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,733',\n",
       " '5,757',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,944',\n",
       " '6,048',\n",
       " '6,048',\n",
       " '6,048',\n",
       " '6,048',\n",
       " '6,153',\n",
       " '6,153',\n",
       " '6,363',\n",
       " '6,584',\n",
       " '6,678',\n",
       " '6,678',\n",
       " '6,678',\n",
       " '8,043',\n",
       " '8,168',\n",
       " '8,201',\n",
       " '8,251',\n",
       " '8,358',\n",
       " '8,568',\n",
       " '8,611',\n",
       " '8,611',\n",
       " '8,621',\n",
       " '8,831',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,926',\n",
       " '8,988',\n",
       " '9,041',\n",
       " '9,093',\n",
       " '9,136',\n",
       " '9,513',\n",
       " '9,513',\n",
       " '9,556',\n",
       " '9,671',\n",
       " '9,723',\n",
       " '9,776',\n",
       " '9,976',\n",
       " '9,976',\n",
       " '10,038',\n",
       " '10,091',\n",
       " '10,143',\n",
       " '10,143',\n",
       " '10,143',\n",
       " '10,190',\n",
       " '10,537',\n",
       " '10,662',\n",
       " '10,668',\n",
       " '10,668',\n",
       " '10,773',\n",
       " '10,773',\n",
       " '10,773',\n",
       " '10,983',\n",
       " '10,983',\n",
       " '11,088',\n",
       " '11,167',\n",
       " '11,298',\n",
       " '11,301',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,403',\n",
       " '11,508',\n",
       " '11,508',\n",
       " '11,666',\n",
       " '11,718',\n",
       " '11,928',\n",
       " '11,971',\n",
       " '11,971',\n",
       " '12,033',\n",
       " '12,033',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,138',\n",
       " '12,348',\n",
       " '12,606',\n",
       " '13,196',\n",
       " '13,609',\n",
       " '14,658',\n",
       " '4,265',\n",
       " '4,265',\n",
       " '4,955',\n",
       " '5,055',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,564',\n",
       " '5,733',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,941',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,942',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,943',\n",
       " '5,944',\n",
       " '5,944',\n",
       " '6,048',\n",
       " '6,153',\n",
       " '6,153',\n",
       " '6,153',\n",
       " '6,363',\n",
       " '6,508',\n",
       " '6,516',\n",
       " '6,521',\n",
       " '6,678',\n",
       " '6,678',\n",
       " '7,480',\n",
       " '7,991',\n",
       " '8,201',\n",
       " '8,306',\n",
       " '8,358',\n",
       " '8,411',\n",
       " '8,621',\n",
       " '8,623',\n",
       " '8,672',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,883',\n",
       " '8,926',\n",
       " '8,926',\n",
       " '8,988',\n",
       " '8,988',\n",
       " '8,988',\n",
       " '8,988',\n",
       " '9,093',\n",
       " '9,136',\n",
       " '9,241',\n",
       " '9,241',\n",
       " '9,513',\n",
       " '9,513',\n",
       " '9,723',\n",
       " '9,723',\n",
       " '9,723',\n",
       " '9,828',\n",
       " '9,828',\n",
       " '9,976',\n",
       " '9,976',\n",
       " '10,038',\n",
       " '10,143',\n",
       " '10,291',\n",
       " '10,406',\n",
       " '10,458',\n",
       " '10,563',\n",
       " '10,563',\n",
       " '10,563',\n",
       " '10,563',\n",
       " '10,668',\n",
       " '10,668',\n",
       " '10,668',\n",
       " ...]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLIGHT_PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4104"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRICE = [] #empty list\n",
    "for i in FLIGHT_PRICE:\n",
    "    PRICE.append(i.replace(',', ''))\n",
    "len(PRICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRLINE_NAME</th>\n",
       "      <th>FLIGHT_CODE</th>\n",
       "      <th>DATE_OF_JOURNEY</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>DESTINATION</th>\n",
       "      <th>DEPARTURE_TIME</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>TOTAL_STOP</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>6E-6413</td>\n",
       "      <td>29/11/2021</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>05:35</td>\n",
       "      <td>07:05</td>\n",
       "      <td>1:30</td>\n",
       "      <td>Non Stop</td>\n",
       "      <td>4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>6E-6207</td>\n",
       "      <td>29/11/2021</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>15:30</td>\n",
       "      <td>17:00</td>\n",
       "      <td>1:30</td>\n",
       "      <td>Non Stop</td>\n",
       "      <td>4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air India</td>\n",
       "      <td>AI-630</td>\n",
       "      <td>29/11/2021</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>21:10</td>\n",
       "      <td>23:05</td>\n",
       "      <td>1:55</td>\n",
       "      <td>Non Stop</td>\n",
       "      <td>4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go First</td>\n",
       "      <td>G8-2607</td>\n",
       "      <td>29/11/2021</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>20:15</td>\n",
       "      <td>21:45</td>\n",
       "      <td>1:30</td>\n",
       "      <td>Non Stop</td>\n",
       "      <td>4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Go First</td>\n",
       "      <td>G8-601</td>\n",
       "      <td>29/11/2021</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>10:50</td>\n",
       "      <td>12:25</td>\n",
       "      <td>1:35</td>\n",
       "      <td>Non Stop</td>\n",
       "      <td>4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-839/822/775</td>\n",
       "      <td>16/03/2022</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>13:30</td>\n",
       "      <td>16:55</td>\n",
       "      <td>27:25</td>\n",
       "      <td>2 Stop(s)</td>\n",
       "      <td>17313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-839/828/775</td>\n",
       "      <td>16/03/2022</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>13:30</td>\n",
       "      <td>16:55</td>\n",
       "      <td>27:25</td>\n",
       "      <td>2 Stop(s)</td>\n",
       "      <td>17313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-833/826/775</td>\n",
       "      <td>16/03/2022</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>07:20</td>\n",
       "      <td>16:55</td>\n",
       "      <td>33:35</td>\n",
       "      <td>2 Stop(s)</td>\n",
       "      <td>17313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-833/828/775</td>\n",
       "      <td>16/03/2022</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>07:20</td>\n",
       "      <td>16:55</td>\n",
       "      <td>33:35</td>\n",
       "      <td>2 Stop(s)</td>\n",
       "      <td>17313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-833/824/775</td>\n",
       "      <td>16/03/2022</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>07:20</td>\n",
       "      <td>16:55</td>\n",
       "      <td>33:35</td>\n",
       "      <td>2 Stop(s)</td>\n",
       "      <td>17313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4104 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AIRLINE_NAME     FLIGHT_CODE DATE_OF_JOURNEY     SOURCE DESTINATION  \\\n",
       "0          IndiGo         6E-6413      29/11/2021     Nagpur      Mumbai   \n",
       "1          IndiGo         6E-6207      29/11/2021     Nagpur      Mumbai   \n",
       "2       Air India          AI-630      29/11/2021     Nagpur      Mumbai   \n",
       "3        Go First         G8-2607      29/11/2021     Nagpur      Mumbai   \n",
       "4        Go First          G8-601      29/11/2021     Nagpur      Mumbai   \n",
       "...           ...             ...             ...        ...         ...   \n",
       "4099      Vistara  UK-839/822/775      16/03/2022  New Delhi     Kolkata   \n",
       "4100      Vistara  UK-839/828/775      16/03/2022  New Delhi     Kolkata   \n",
       "4101      Vistara  UK-833/826/775      16/03/2022  New Delhi     Kolkata   \n",
       "4102      Vistara  UK-833/828/775      16/03/2022  New Delhi     Kolkata   \n",
       "4103      Vistara  UK-833/824/775      16/03/2022  New Delhi     Kolkata   \n",
       "\n",
       "     DEPARTURE_TIME ARRIVAL_TIME DURATION TOTAL_STOP  PRICE  \n",
       "0             05:35        07:05     1:30   Non Stop   4566  \n",
       "1             15:30        17:00     1:30   Non Stop   4566  \n",
       "2             21:10        23:05     1:55   Non Stop   4566  \n",
       "3             20:15        21:45     1:30   Non Stop   4567  \n",
       "4             10:50        12:25     1:35   Non Stop   4567  \n",
       "...             ...          ...      ...        ...    ...  \n",
       "4099          13:30        16:55    27:25  2 Stop(s)  17313  \n",
       "4100          13:30        16:55    27:25  2 Stop(s)  17313  \n",
       "4101          07:20        16:55    33:35  2 Stop(s)  17313  \n",
       "4102          07:20        16:55    33:35  2 Stop(s)  17313  \n",
       "4103          07:20        16:55    33:35  2 Stop(s)  17313  \n",
       "\n",
       "[4104 rows x 10 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of Used car data from yatra.com\n",
    "FLIGHT_PRICE_PREDICTION = pd.DataFrame({})\n",
    "FLIGHT_PRICE_PREDICTION['AIRLINE_NAME'] = AIRLINES_NAME \n",
    "FLIGHT_PRICE_PREDICTION['FLIGHT_CODE'] = FLIGHTS_CODE\n",
    "FLIGHT_PRICE_PREDICTION['DATE_OF_JOURNEY'] =DATE_OF_JOURNEY \n",
    "FLIGHT_PRICE_PREDICTION['SOURCE'] = SOURCES\n",
    "FLIGHT_PRICE_PREDICTION['DESTINATION'] = DESTINATIONS\n",
    "FLIGHT_PRICE_PREDICTION['DEPARTURE_TIME'] = DEPARTURE_T\n",
    "FLIGHT_PRICE_PREDICTION['ARRIVAL_TIME'] = ARRIVAL_T\n",
    "FLIGHT_PRICE_PREDICTION['DURATION'] = DURATION\n",
    "FLIGHT_PRICE_PREDICTION['TOTAL_STOP'] = TOTAL_STOPS\n",
    "FLIGHT_PRICE_PREDICTION['PRICE'] = PRICE\n",
    "FLIGHT_PRICE_PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLIGHT_PRICE_PREDICTION.to_csv(\"FlightPricePrediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
